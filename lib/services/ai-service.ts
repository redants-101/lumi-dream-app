/**
 * AI æœåŠ¡
 * å¤„ç† AI æ¨¡å‹é€‰æ‹©å’Œæ–‡æœ¬ç”Ÿæˆ
 */

import { generateText } from "ai"
import { createOpenRouter } from "@openrouter/ai-sdk-provider"
import { MODEL_PARAMS } from "@/lib/ai-config"
import { getCurrentPrompt, PROMPT_VERSION } from "@/lib/prompts"
import { getModelForTier, getFallbackModel, getDowngradeThreshold, type UserTier } from "@/lib/usage-limits"
import type { UsageData } from "./usage-service"

/**
 * é…ç½® OpenRouter å®˜æ–¹ Provider
 */
const openrouter = createOpenRouter({
  apiKey: process.env.OPENROUTER_API_KEY,
  headers: {
    "HTTP-Referer": process.env.NEXT_PUBLIC_APP_URL || "https://www.lumidreams.app",
    "X-Title": "Lumi Dream Interpreter",
  },
})

/**
 * AI è§£æç»“æœ
 */
export interface InterpretationResult {
  interpretation: string
  metadata: {
    userTier: UserTier
    model: string
    isDowngraded: boolean
    promptVersion: string
    usage: {
      inputTokens: number
      outputTokens: number
      totalTokens: number
    }
    finishReason: string
  }
}

/**
 * é€‰æ‹© AI æ¨¡å‹ï¼ˆåŒ…å«é™çº§é€»è¾‘ï¼‰
 */
export function selectModel(
  tier: UserTier,
  usageData?: UsageData
): { modelId: string; isDowngraded: boolean } {
  let modelId = getModelForTier(tier)
  let isDowngraded = false
  
  // Pro ç”¨æˆ·é™çº§åˆ¤æ–­
  if (tier === "pro" && usageData) {
    const downgradeThreshold = getDowngradeThreshold(tier) || 100
    
    if (usageData.monthly >= downgradeThreshold) {
      const fallback = getFallbackModel(tier)
      if (fallback) {
        modelId = fallback
        isDowngraded = true
        console.log(
          `[AIService] ğŸ”„ Pro user downgraded (${usageData.monthly}/200 used, threshold: ${downgradeThreshold}) â†’ ${modelId}`
        )
      }
    } else if (usageData.monthly > 0) {
      console.log(
        `[AIService] ğŸš€ Pro user using premium model (${usageData.monthly}/${downgradeThreshold})`
      )
    }
  } else {
    console.log(`[AIService] ğŸ¤– User tier: ${tier} â†’ Model: ${modelId}`)
  }
  
  return { modelId, isDowngraded }
}

/**
 * ç”Ÿæˆæ¢¦å¢ƒè§£æ
 */
export async function generateDreamInterpretation(
  dream: string,
  tier: UserTier,
  usageData?: UsageData
): Promise<InterpretationResult> {
  const { modelId, isDowngraded } = selectModel(tier, usageData)
  
  // ä½¿ç”¨é›†ä¸­ç®¡ç†çš„æç¤ºè¯
  const result = await generateText({
    model: openrouter(modelId),
    prompt: getCurrentPrompt(dream),
    temperature: MODEL_PARAMS.temperature,
    topP: MODEL_PARAMS.topP,
    frequencyPenalty: MODEL_PARAMS.frequencyPenalty,
    presencePenalty: MODEL_PARAMS.presencePenalty,
  })
  
  // è®°å½• AI ä½¿ç”¨æƒ…å†µ
  console.log("[AIService] AI Interpretation Stats:", {
    userTier: tier,
    model: modelId,
    isDowngraded: isDowngraded,
    promptVersion: PROMPT_VERSION,
    inputTokens: result.usage.inputTokens,
    outputTokens: result.usage.outputTokens,
    totalTokens: result.usage.totalTokens,
    finishReason: result.finishReason,
  })
  
  return {
    interpretation: result.text,
    metadata: {
      userTier: tier,
      model: modelId,
      isDowngraded: isDowngraded,
      promptVersion: PROMPT_VERSION,
      usage: {
        inputTokens: result.usage.inputTokens || 0,
        outputTokens: result.usage.outputTokens || 0,
        totalTokens: result.usage.totalTokens || 0,
      },
      finishReason: result.finishReason,
    },
  }
}

